{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Берём натренированную VGG16, отрезаем голову и прогоняем её на большом кол-ве нагенеренных примеров (идея стырена отсюда: https://blog.keras.io/building-powerful-image-classification-models-using-very-little-data.html)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/home/bfilippov/kaggle/whiteboard\n"
     ]
    }
   ],
   "source": [
    "cd .."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n"
     ]
    }
   ],
   "source": [
    "import keras\n",
    "import pandas as pd\n",
    "import ast\n",
    "\n",
    "train = pd.read_csv('source/train.csv')\n",
    "test = pd.read_csv('source/test.csv')\n",
    "train['labels'] = train['labels'].map(ast.literal_eval)\n",
    "test['labels'] = test['labels'].map(ast.literal_eval)\n",
    "\n",
    "valid = train.sample(frac=0.2, random_state=1313)\n",
    "train = train.drop(valid.index)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The autoreload extension is already loaded. To reload it, use:\n",
      "  %reload_ext autoreload\n"
     ]
    }
   ],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2\n",
    "import tensorflow as tf\n",
    "\n",
    "from keras.layers import Dense, Flatten, Input\n",
    "from keras.models import Model\n",
    "from keras import backend as K\n",
    "\n",
    "from models.model_zoo import whiteboard_detector, whiteboard_loss\n",
    "from keras.applications import VGG16\n",
    "from models.image_generator import whiteboard_images\n",
    "\n",
    "sess = tf.Session()\n",
    "K.set_session(sess)\n",
    "\n",
    "input_height = 224\n",
    "input_width = 224\n",
    "\n",
    "input_image = Input(shape=(input_height, input_width, 3))\n",
    "resnet = VGG16(input_tensor=input_image, include_top=False)\n",
    "\n",
    "for l in resnet.layers:\n",
    "    l.trainable=False\n",
    "    \n",
    "resnet = Flatten()(resnet.output)\n",
    "\n",
    "vgg16 = Model(input=input_image, output=resnet)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "img_dir = 'source/'\n",
    "img_size = (input_height, input_width)\n",
    "\n",
    "train_imgs = whiteboard_images(train, img_dir, img_size, batch_size=5, seed=1313)\n",
    "valid_imgs = whiteboard_images(valid, img_dir, img_size, batch_size=5, seed=1313)\n",
    "test_imgs = whiteboard_images(test, img_dir, img_size, batch_size=5, seed=1313)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processed 0 images for vgg16_train.npy\n",
      "Processed 50 images for vgg16_train.npy\n",
      "Processed 100 images for vgg16_train.npy\n",
      "Processed 150 images for vgg16_train.npy\n",
      "Processed 200 images for vgg16_train.npy\n",
      "Processed 250 images for vgg16_train.npy\n",
      "Processed 300 images for vgg16_train.npy\n",
      "Processed 350 images for vgg16_train.npy\n",
      "Processed 400 images for vgg16_train.npy\n",
      "Processed 450 images for vgg16_train.npy\n",
      "Processed 500 images for vgg16_train.npy\n",
      "Processed 550 images for vgg16_train.npy\n",
      "Processed 600 images for vgg16_train.npy\n",
      "Processed 650 images for vgg16_train.npy\n",
      "Processed 700 images for vgg16_train.npy\n",
      "Processed 750 images for vgg16_train.npy\n",
      "Processed 800 images for vgg16_train.npy\n",
      "Processed 850 images for vgg16_train.npy\n",
      "Processed 900 images for vgg16_train.npy\n",
      "Processed 950 images for vgg16_train.npy\n",
      "Processed 1000 images for vgg16_train.npy\n",
      "Processed 1050 images for vgg16_train.npy\n",
      "Processed 1100 images for vgg16_train.npy\n",
      "Processed 1150 images for vgg16_train.npy\n",
      "Processed 1200 images for vgg16_train.npy\n",
      "Processed 1250 images for vgg16_train.npy\n",
      "Processed 1300 images for vgg16_train.npy\n",
      "Processed 1350 images for vgg16_train.npy\n",
      "Processed 1400 images for vgg16_train.npy\n",
      "Processed 1450 images for vgg16_train.npy\n",
      "Processed 1500 images for vgg16_train.npy\n",
      "Processed 1550 images for vgg16_train.npy\n",
      "Processed 1600 images for vgg16_train.npy\n",
      "Processed 1650 images for vgg16_train.npy\n",
      "Processed 1700 images for vgg16_train.npy\n",
      "Processed 1750 images for vgg16_train.npy\n",
      "Processed 1800 images for vgg16_train.npy\n",
      "Processed 1850 images for vgg16_train.npy\n",
      "Processed 1900 images for vgg16_train.npy\n",
      "Processed 1950 images for vgg16_train.npy\n",
      "Processed 2000 images for vgg16_train.npy\n",
      "Processed 2050 images for vgg16_train.npy\n",
      "Processed 2100 images for vgg16_train.npy\n",
      "Processed 2150 images for vgg16_train.npy\n",
      "Processed 2200 images for vgg16_train.npy\n",
      "Processed 2250 images for vgg16_train.npy\n",
      "Processed 2300 images for vgg16_train.npy\n",
      "Processed 2350 images for vgg16_train.npy\n",
      "Processed 2400 images for vgg16_train.npy\n",
      "Processed 2450 images for vgg16_train.npy\n",
      "Processed 2500 images for vgg16_train.npy\n",
      "Processed 2550 images for vgg16_train.npy\n",
      "Processed 2600 images for vgg16_train.npy\n",
      "Processed 2650 images for vgg16_train.npy\n",
      "Processed 2700 images for vgg16_train.npy\n",
      "Processed 2750 images for vgg16_train.npy\n",
      "Processed 2800 images for vgg16_train.npy\n",
      "Processed 2850 images for vgg16_train.npy\n",
      "Processed 2900 images for vgg16_train.npy\n",
      "Processed 2950 images for vgg16_train.npy\n",
      "Processed 3000 images for vgg16_train.npy\n",
      "Processed 3050 images for vgg16_train.npy\n",
      "Processed 3100 images for vgg16_train.npy\n",
      "Processed 3150 images for vgg16_train.npy\n",
      "Processed 3200 images for vgg16_train.npy\n",
      "Processed 3250 images for vgg16_train.npy\n",
      "Processed 3300 images for vgg16_train.npy\n",
      "Processed 3350 images for vgg16_train.npy\n",
      "Processed 3400 images for vgg16_train.npy\n",
      "Processed 3450 images for vgg16_train.npy\n",
      "Processed 3500 images for vgg16_train.npy\n",
      "Processed 3550 images for vgg16_train.npy\n",
      "Processed 3600 images for vgg16_train.npy\n",
      "Processed 3650 images for vgg16_train.npy\n",
      "Processed 3700 images for vgg16_train.npy\n",
      "Processed 3750 images for vgg16_train.npy\n",
      "Processed 3800 images for vgg16_train.npy\n",
      "Processed 3850 images for vgg16_train.npy\n",
      "Processed 3900 images for vgg16_train.npy\n",
      "Processed 3950 images for vgg16_train.npy\n",
      "Processed 4000 images for vgg16_train.npy\n",
      "Processed 4050 images for vgg16_train.npy\n",
      "Processed 4100 images for vgg16_train.npy\n",
      "Processed 4150 images for vgg16_train.npy\n",
      "Processed 4200 images for vgg16_train.npy\n",
      "Processed 4250 images for vgg16_train.npy\n",
      "Processed 4300 images for vgg16_train.npy\n",
      "Processed 4350 images for vgg16_train.npy\n",
      "Processed 4400 images for vgg16_train.npy\n",
      "Processed 4450 images for vgg16_train.npy\n",
      "Processed 4500 images for vgg16_train.npy\n",
      "Processed 4550 images for vgg16_train.npy\n",
      "Processed 4600 images for vgg16_train.npy\n",
      "Processed 4650 images for vgg16_train.npy\n",
      "Processed 4700 images for vgg16_train.npy\n",
      "Processed 4750 images for vgg16_train.npy\n",
      "Processed 4800 images for vgg16_train.npy\n",
      "Processed 4850 images for vgg16_train.npy\n",
      "Processed 4900 images for vgg16_train.npy\n",
      "Processed 4950 images for vgg16_train.npy\n",
      "Processed 5000 images for vgg16_train.npy\n",
      "Processed 5050 images for vgg16_train.npy\n",
      "Processed 5100 images for vgg16_train.npy\n",
      "Processed 5150 images for vgg16_train.npy\n",
      "Processed 5200 images for vgg16_train.npy\n",
      "Processed 5250 images for vgg16_train.npy\n",
      "Processed 5300 images for vgg16_train.npy\n",
      "Processed 5350 images for vgg16_train.npy\n",
      "Processed 5400 images for vgg16_train.npy\n",
      "Processed 5450 images for vgg16_train.npy\n",
      "Processed 5500 images for vgg16_train.npy\n",
      "Processed 5550 images for vgg16_train.npy\n",
      "Processed 5600 images for vgg16_train.npy\n",
      "Processed 5650 images for vgg16_train.npy\n",
      "Processed 5700 images for vgg16_train.npy\n",
      "Processed 5750 images for vgg16_train.npy\n",
      "Processed 5800 images for vgg16_train.npy\n",
      "Processed 5850 images for vgg16_train.npy\n",
      "Processed 5900 images for vgg16_train.npy\n",
      "Processed 5950 images for vgg16_train.npy\n",
      "Processed 6000 images for vgg16_train.npy\n",
      "Processed 6050 images for vgg16_train.npy\n",
      "Processed 6100 images for vgg16_train.npy\n",
      "Processed 6150 images for vgg16_train.npy\n",
      "Processed 6200 images for vgg16_train.npy\n",
      "Processed 6250 images for vgg16_train.npy\n",
      "Processed 6300 images for vgg16_train.npy\n",
      "Processed 6350 images for vgg16_train.npy\n",
      "Processed 6400 images for vgg16_train.npy\n",
      "Processed 6450 images for vgg16_train.npy\n",
      "Processed 6500 images for vgg16_train.npy\n",
      "Processed 6550 images for vgg16_train.npy\n",
      "Processed 6600 images for vgg16_train.npy\n",
      "Processed 6650 images for vgg16_train.npy\n",
      "Processed 6700 images for vgg16_train.npy\n",
      "Processed 6750 images for vgg16_train.npy\n",
      "Processed 6800 images for vgg16_train.npy\n",
      "Processed 6850 images for vgg16_train.npy\n",
      "Processed 6900 images for vgg16_train.npy\n",
      "Processed 6950 images for vgg16_train.npy\n",
      "Processed 7000 images for vgg16_train.npy\n",
      "Processed 7050 images for vgg16_train.npy\n",
      "Processed 7100 images for vgg16_train.npy\n",
      "Processed 7150 images for vgg16_train.npy\n",
      "Processed 7200 images for vgg16_train.npy\n",
      "Processed 7250 images for vgg16_train.npy\n",
      "Processed 7300 images for vgg16_train.npy\n",
      "Processed 7350 images for vgg16_train.npy\n",
      "Processed 7400 images for vgg16_train.npy\n",
      "Processed 7450 images for vgg16_train.npy\n",
      "Processed 7500 images for vgg16_train.npy\n",
      "Processed 7550 images for vgg16_train.npy\n",
      "Processed 7600 images for vgg16_train.npy\n",
      "Processed 7650 images for vgg16_train.npy\n",
      "Processed 7700 images for vgg16_train.npy\n",
      "Processed 7750 images for vgg16_train.npy\n",
      "Processed 7800 images for vgg16_train.npy\n",
      "Processed 7850 images for vgg16_train.npy\n",
      "Processed 7900 images for vgg16_train.npy\n",
      "Processed 7950 images for vgg16_train.npy\n",
      "Processed 8000 images for vgg16_train.npy\n",
      "Processed 8050 images for vgg16_train.npy\n",
      "Processed 8100 images for vgg16_train.npy\n",
      "Processed 8150 images for vgg16_train.npy\n",
      "Processed 8200 images for vgg16_train.npy\n",
      "Processed 8250 images for vgg16_train.npy\n",
      "Processed 8300 images for vgg16_train.npy\n",
      "Processed 8350 images for vgg16_train.npy\n",
      "Processed 8400 images for vgg16_train.npy\n",
      "Processed 8450 images for vgg16_train.npy\n",
      "Processed 8500 images for vgg16_train.npy\n",
      "Processed 8550 images for vgg16_train.npy\n",
      "Processed 8600 images for vgg16_train.npy\n",
      "Processed 8650 images for vgg16_train.npy\n",
      "Processed 8700 images for vgg16_train.npy\n",
      "Processed 8750 images for vgg16_train.npy\n",
      "Processed 8800 images for vgg16_train.npy\n",
      "Processed 8850 images for vgg16_train.npy\n",
      "Processed 8900 images for vgg16_train.npy\n",
      "Processed 8950 images for vgg16_train.npy\n",
      "Processed 9000 images for vgg16_train.npy\n",
      "Processed 9050 images for vgg16_train.npy\n",
      "Processed 9100 images for vgg16_train.npy\n",
      "Processed 9150 images for vgg16_train.npy\n",
      "Processed 9200 images for vgg16_train.npy\n",
      "Processed 9250 images for vgg16_train.npy\n",
      "Processed 9300 images for vgg16_train.npy\n",
      "Processed 9350 images for vgg16_train.npy\n",
      "Processed 9400 images for vgg16_train.npy\n",
      "Processed 9450 images for vgg16_train.npy\n",
      "Processed 9500 images for vgg16_train.npy\n",
      "Processed 9550 images for vgg16_train.npy\n",
      "Processed 9600 images for vgg16_train.npy\n",
      "Processed 9650 images for vgg16_train.npy\n",
      "Processed 9700 images for vgg16_train.npy\n",
      "Processed 9750 images for vgg16_train.npy\n",
      "Processed 9800 images for vgg16_train.npy\n",
      "Processed 9850 images for vgg16_train.npy\n",
      "Processed 9900 images for vgg16_train.npy\n",
      "Processed 9950 images for vgg16_train.npy\n",
      "Saved train data\n",
      "Processed 0 images for vgg16_valid.npy\n",
      "Processed 50 images for vgg16_valid.npy\n",
      "Processed 100 images for vgg16_valid.npy\n",
      "Processed 150 images for vgg16_valid.npy\n",
      "Processed 200 images for vgg16_valid.npy\n",
      "Saved validation data\n",
      "Processed 0 images for vgg16_test.npy\n",
      "Processed 50 images for vgg16_test.npy\n",
      "Processed 100 images for vgg16_test.npy\n",
      "Processed 150 images for vgg16_test.npy\n",
      "Processed 200 images for vgg16_test.npy\n",
      "Saved test data\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "train_size = 10 * 1000\n",
    "test_size = 250\n",
    "valid_size = 250\n",
    "\n",
    "def save_batch(fpath, generator, size, batch_size=50):\n",
    "    f = open(fpath, 'w+b')\n",
    "    for i in range(0, size, batch_size):\n",
    "        batch = vgg16.predict_generator(generator, batch_size)\n",
    "        np.save(f, batch)\n",
    "        print(\"Processed\", i, \"images for\", fpath)\n",
    "\n",
    "save_batch('vgg16_train.npy', train_imgs, train_size)\n",
    "print(\"Saved train data\")\n",
    "\n",
    "save_batch(\"vgg16_valid.npy\", valid_imgs, valid_size)\n",
    "print(\"Saved validation data\")\n",
    "\n",
    "save_batch(\"vgg16_test.npy\", test_imgs, test_size)\n",
    "print(\"Saved test data\")\n",
    "    "
   ]
  }
 ],
 "metadata": {
  "anaconda-cloud": {},
  "kernelspec": {
   "display_name": "Python [conda root]",
   "language": "python",
   "name": "conda_root"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
