{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Сравнение разных детекторов досок по validation loss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/home/bfilippov/kaggle/whiteboard\n"
     ]
    }
   ],
   "source": [
    "cd .."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n"
     ]
    }
   ],
   "source": [
    "import keras\n",
    "import pandas as pd\n",
    "import ast\n",
    "import numpy as np \n",
    "import cv2 \n",
    "\n",
    "\n",
    "train = pd.read_csv('source/train.csv')\n",
    "test = pd.read_csv('source/test.csv')\n",
    "train['labels'] = train['labels'].map(ast.literal_eval)\n",
    "test['labels'] = test['labels'].map(ast.literal_eval)\n",
    "\n",
    "valid = train.sample(frac=0.2, random_state=1313)\n",
    "train = train.drop(valid.index)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "nb_cv_features = 5\n",
    "\n",
    "def cv_feature_maps(image):\n",
    "    alpha = image[:, :, 3].copy() # special mask used to ignore image-augmentation artifacts\n",
    "    gray = (cv2.cvtColor(image[:, :, :3].astype(np.float32), cv2.COLOR_RGB2GRAY) * 255).astype(np.uint8)\n",
    "    edges = cv2.Canny(gray, 100, 250)\n",
    "    lines = cv2.HoughLinesP(edges, 1, np.pi/180, 25, minLineLength=50, maxLineGap=50)\n",
    "\n",
    "    corners = cv2.cornerHarris(edges,2,3,0.01)\n",
    "    corners = cv2.dilate(corners,None)\n",
    "    \n",
    "    hough = np.zeros(gray.shape, np.float)\n",
    "\n",
    "    for line in lines:\n",
    "        x1, y1, x2, y2 = line[0]\n",
    "        cv2.line(hough, (x1, y1), (x2, y2), 1, 2)\n",
    "    \n",
    "    def norm(img):\n",
    "        return cv2.normalize(img, img, 0, 1, norm_type=cv2.NORM_MINMAX, \n",
    "                             dtype=cv2.CV_32F)\n",
    "    feature_maps = [norm(img) for img in [gray, edges, corners, hough, alpha]]\n",
    "    return np.stack(feature_maps, axis=2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2\n",
    "import tensorflow as tf\n",
    "\n",
    "from keras import backend as K\n",
    "\n",
    "sess = tf.Session()\n",
    "K.set_session(sess)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "class PatchLabelIterator:\n",
    "    line_thickness = 2\n",
    "    def __init__(self, whiteboard_images, model):\n",
    "        self.whiteboard_images = whiteboard_images\n",
    "        self.out_size = model.out_size[::-1]\n",
    "        self.patch_size = model.patch_size\n",
    "        \n",
    "    def __point(self, batch, k):\n",
    "        x_val = int(batch[k] // self.patch_size)\n",
    "        y_val = int(batch[k + 4] // self.patch_size)            \n",
    "        return x_val, y_val\n",
    "    \n",
    "    def __next__(self):\n",
    "        batch_x, batch_y = next(self.whiteboard_images)\n",
    "        patch_x = np.zeros(batch_x.shape[:-1] + (nb_cv_features,))\n",
    "        patch_y = np.zeros((batch_y.shape[0],) + self.out_size + (1,))\n",
    "        for i, batch in enumerate(batch_y):\n",
    "            patch_x[i] = cv_feature_maps(batch_x[i])\n",
    "            if batch[0]:\n",
    "                for a, b in [(2, 3), (3, 4), (4, 5), (5, 2)]:\n",
    "                    cv2.line(patch_y[i], self.__point(batch_y[i], a), \n",
    "                             self.__point(batch_y[i], b), 1, self.line_thickness)\n",
    "        return patch_x, patch_y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from models.image_generator import whiteboard_images\n",
    "\n",
    "def validate(model):\n",
    "    img_size = (model.height, model.width)\n",
    "    img_dir = 'source'\n",
    "    batch_size = 32\n",
    "    val_samples = 2048\n",
    "\n",
    "    def patch(gen):\n",
    "        return PatchLabelIterator(gen, model)\n",
    "\n",
    "    valid_imgs = patch(whiteboard_images(valid, img_dir, img_size, batch_size=batch_size, seed=1313))\n",
    "\n",
    "    return model.model.evaluate_generator(valid_imgs, val_samples)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.27243718504905701"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from models.model_zoo import wide_whiteboard_detector, baseline_whiteboard_detector\n",
    "\n",
    "validate(baseline_whiteboard_detector())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.27417239546775818"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "validate(wide_whiteboard_detector())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.32326844334602356"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from models.model_zoo import residual_detector_4_blocks\n",
    "\n",
    "validate(residual_detector_4_blocks())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.20618212223052979"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from models.model_zoo import residual_detector_6_blocks\n",
    "\n",
    "validate(residual_detector_6_blocks())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "anaconda-cloud": {},
  "kernelspec": {
   "display_name": "Python [conda root]",
   "language": "python",
   "name": "conda_root"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
